#### Spark input sources

- File source: txt, csv, json, orc 등
- Kafka source: Kafka broker를 사용함
- Socket source: UTF8 text data from socket connection(테스팅 목적으로만) 



#### Spark의 장점

- unification of disparate 데이터 처리 능력
- Spark streaming receivers가 병렬로 데이터를 받아서 스파크 workers nodes에 쌓으면, 스파크 엔진이 짧은 테스크를 돌려 배치 처리를 한다.
- 이는 곧 효율적인 로드밸런싱과 빠른 복구를 가능하게 한다.



#### Stream processing

- 데이터들이 지속적으로 유입되고 나가는 과정에서 분석/SQL을 수행하는 것
- 데이터가 이동 중이거나, 생성되어 수신되는 즉시 처리하는 실시간 분석
- 스트림 프로세싱 등장 후, 기존의 배치 형태를 띄고 있던 데이터 처리 파이프라인이 실시간적이고 지속적으로 데이터 처리 및 분석 가능하게 됨
- 스트림 처리 시스템 + 배치 처리 시스템 모두 갖추어 실시간+정확성 높이는 형태로 발전
- Event Happen => Analytics => Action의 과정에 지연이 거의 없음
- 데이터를 저장 후 분석하는 것이 아니기 때문에, 다른 정적 데이터 프로세싱보다 더 큰 데이터 용량 다룰 수 있음
- 기존 주기적 데이터 계산 배치와 정적 데이터 분석과 대조를 이루어 지속적으로 들어오는 데이터를 점차적으로 분석하기 때문에 실시간 처리에 최적화 되어 있음
- 대규모 공유 DB에 대한 의존성을 줄일 수 있어 MSA 방식에 친화적이다.

