# 전) PMP 계획서

## 주제 및 컨셉

> 서비스 명 - TweeTrend

코로나 연관어 기반 트렌드 분석 대시보드 서비스

- 사회적으로 큰 이슈인 '코로나' 에 대해 SNS(twitter)에서 언급되는 키워드에 대한 실시간 피드와  이를 바탕으로 분석한 통계자료를 사용자에게 대시보드의 형태로 제공하는 서비스를 개발한다.

- Twitter에서 언급되는 코로나 관련 키워드에 대한 실시간 피드 제공과, 키워드를 분석한 통계자료를 사용자에게 대시보드의 형태로 제공하는 서비스를 개발한다.

- 이후 특정 주제에 국한되지 않고, 유저가 검색한 키워드에 대한 트렌드 분석 페이지를 제공하는 서비스로 확장한다.

- 트위터 외에 다른 SNS(인스타그램 등)의 전체적인 트렌드를 분석하여 제공하는 서비스로 확장한다.

‣ 

- <details><summary>이전에 작성한 목표</summary>

   ### 목표

   #### __개인적 목표__

   - 추연호

      - React + TypeScript 기술 스택에 대한 숙련도를 늘리고 싶다. 

      - 상태관리 라이브러리(Redux)에 익숙해지고 싶다.

      - 컴포넌트의 스타일링과 기능을 잘 나눠보고 싶다. (프레젠테이셔널 / 컨테이너 패턴)

      - 디자인 시스템을 구축하는 워크플로우를 경험하고 싶다.

      - 데이터 시각화 경험을 하고 싶다.

      - WebSocket을 활용해 실시간 연동을 구현해보고 싶다.

   - 정석준 

      - 하나의 완성된 웹 서비스를 개발하며 전체적인 개념을 잡고 싶다.

      - 팀 프로젝트를 통해 팀으로서 협업을 통해 하나의 목표를 성취하는 경험을 기르고 싶다.

      - 백엔드에서 이루어지는 역할을 명확히 이해하고 그에 맞춰 API Server를 성공적으로 완성하고 싶다.

      - 한 단계 더 나아가서 MSA 구축을 경험하고 개념적인 틀을 쌓고 싶다. 

   - 이규은

      - 대용량 데이터를 수집하고, 알맞게 처리하고 싶다.

      - 대용량 데이터를 잘 활용하기 위한 데이터 가공을 경험하고 싶다.

      - 분산 처리 시스템 전체에 대해 파악하고, 잘 활용하여 분산 처리의 이점을 직접 경험하고 싶다.

      - 분업과 이슈 관리 등 프로젝트를 체계적으로 계획하고 관리하는 경험을 하고 싶다.

   - 조인식

      - 데이터 처리에 대한 관심을 바탕으로 대용량 데이터를 이용하여 특정 서비스를 제공하는 것을 완성해 보고 싶다.

      - 데이터 파이프라인의 전체적인 흐름 파악과 여러 종류의 프레임워크 별 장단점과 사용 방법을 익히고 싶다.

      - 프로젝트 설계 및 관리 등 간과했던 영역에 대한 경험을 쌓고 싶다.

      - 역할이 명확히 분리된 환경에서의 협업을 경험해 보고 싶다.

   - 김가윤

      - 데이터 수집, 저장, 처리, 분석, 시각화까지 일련의 과정을 경험하고 기술적 스택을 쌓고 싶다.

      - 데이터처리 전반에 관한 End-to-End를 경험해보고 싶다.

      - 데이터 분산 처리 기술에 대해 배워보고 싶다.

      - Spark 기술 활용법에 대해 자세히 익히고 싶다.

      - 분산형 DB에 대해 공부하고 마스터하고 싶다.

  </details>

## 팀 목표

- Tweetdeck과 SomeTrend를 벤치마킹하여 각자 관심있는 기술 습득 및 구현하는 것을 목표로 TweeTrend 서비스로 자연스럽게 통합하는 것.

- TweeTrend 서비스를 개발하면서 사용한 기술에 대해 서로에게 설명할 수 있을 정도의 상태가 되는 것.

### 매니지먼트 요소 및 관리 방안

- 시간 및 개발 일정

   → 팀 프로젝트 기간을 단계별로 나눠 각 단계의 목표를 정하고, 각 목표에 맞춰 각자의 기능을 개발한다.

   → 해야 할 일의 우선순위를 파악하고 작은 단위로 일을 나누어 체계적으로 진행한다

   → 각자 약속한 개발 일정을 준수하자 (일정을 지키지 못하면, 납득할 수 있는 이유가 있어야 한다.)

   → 매일 스크럼미팅을 통해 각자의 진행 상황을 공유한다

- 경험 부족

   → 그 만큼 학습해야 할 지식이 많다 

   → 지식 습득과 개발 사이의 효율적인 시간 관리가 필요하다

   → 이슈와 학습 내용에 대해 체계적이고 자세하게 기록하고 개발에 적용한다 (JIRA와 gitlab 활용)

   → 구조적인 고민, 성능 및 최적화에 대한 고민보다는 우선 구현할 수 있는 것부터 구현하고 나중에 개선한다

   → 리서치를 통해 공유하면 좋은 자료는 함께 공유한다.

- 에러 해결

   → 혼자 고민하지 말고 팀원의 도움을 구하기 위해 적극적으로 질문한다. (알려주는 사람이 더 배울 수 있도록)

   → 에러 해결 후 notion에 공유하여 동일한 문제 해결에 대해 다른 팀원들에게 도움을 제공한다.

- 인터페이스

   → 인터페이스를 맞춰야하는 당사자간 회의를 통해 의논한다. 

   → 개발 중에 다른 사람과 협의해야 하는 문제가 있다면, 빨리 문제 상황을 의논한다.

### 팀 빌딩/담당 역할

- 프론트 및 인증 서버 개발 → 추연호

   1. 전체 페이지 디자인

   1. 데이터 시각화 컴포넌트 개발

   1. Web Socket을 활용한 실시간 피드 컬럼 개발

   1. 로그인, 회원가입 페이지 개발

   1. 관심 주제 입력 폼 제작

   1. 인증 서버 개발

- 백엔드 → 정석준

   1. 데이터 조회 및 프론트 전달

   1. 백엔드 기능 개발

   1. redis를 활용한 캐싱

- 데이터 처리

   1. 데이터 수집 및 분산 처리(카프카) → 조인식

   1. 분산 데이터 가공 및 전처리(스파크) → 김가윤

   1. 가공 데이터 분산 저장 및 전달(분산형 DB) → 이규은

      ### 협업 Tool

- Gitlab: 개발 코드 공유

- Jira: 마일스톤 일정에 따라 Sprint 생성 후 각자 개발 사항 issue등록 후 진행 상황 고유 

- Notion: 회의록, PMP, Code Convention 등 문서작성 후 공유

- Teams: 오전 daily scrum, 빅스마일팀 회의, 웹개발팀, 데이터팀 회의 진행

### 기능 정의서

- 회원가입 + 로그인 기능

   - 일반 회원가입

   - 이메일 인증

   - + @ 소셜 로그인 (트위터 or 구글 + 카카오)

- 유저 관심 주제 관리

   - 회원가입이 완료되면 폼을 제공해 유저에게 관심 주제를 입력받는다. ex) 코로나, BTS, 넷플릭스 ...

   - 유저는 관심있는 주제를 추가하거나 삭제할 수 있다.

   - 메인 화면에는 하나의 주제에 대한 통계 데이터가 보여지고, 상단 탭으로 유저가 관심있는 주제별로 이동할 수 있다.

- 메인 화면에는 키워드에 대한 여러 통계 데이터를 보여준다.

   - 유저는 일간, 주간, 월간, 3개월간 통계를 선택할 수 있다.

   - 언급량 추이 : 해시태그의 언급량 추이 그래프를 보여준다.

   - 개별 사용자 추이 : 해시태그를 사용한 개별 사용자 추이 그래프를 보여준다.

   - 실시간 피드 : 키워드 해시태그가 포함된 실시간 피드를 보여준다.

      - Web Socket을 활용하여 실시간으로 업데이트 된다.

      - 무한 스크롤을 구현한다.

   - 컨텐츠 분석

      - 기간 내에 가장 인기있는 게시물(가능하다면 목록)을 보여준다.

      - 기간 내에 해당 해시태그를 가장 많이 사용한 사용자(가능하다면 목록)을 보여준다.

   - 연관어 분석

      - 관련 키워드를 word cloud / bubble chart 형태로 보여준다.

      - 연관어 순위를 보여준다.

      - 연관어 빈도수를 비교하는 그래프를 보여준다.

   #### 이슈

### 아키텍처 설계

![전-PMP-계획서-image-0](images/전-PMP-계획서-image-0.png)

![전-PMP-계획서-image-1](images/전-PMP-계획서-image-1.png)

![전-PMP-계획서-image-2](images/전-PMP-계획서-image-2.png)

![전-PMP-계획서-image-3](images/전-PMP-계획서-image-3.png)

[Cloudcraft - Draw AWS diagrams](https://app.cloudcraft.co/view/60e50b09-952e-47a7-be48-29307faa77bd?key=mX3xEz6obXvNNyA3LV1DPw)

- Data Processing 

   - Tweeter API → Kafka → Spark Streaming → Cassandra DB → 1. 실시간 피드 API(Django) 2. Spark→ 키워드 API(Django) ⇒ API Gateway(Django)

- BackEnd

   - API Server : Nginx → web socket → gunicorn(or uWSGI)  → Django

   - Auth Server : NestJS or ExpressJS + MySQL ⇒ API Gateway

   - [수정사항] 
Real-Time Feed API Server(web socket) → Daphne → Nginx
Keywords API Server → uWSGI(or gunicorn) → Nginx


- FrontEnd 

   - Main : React + TypeScript + Redux + Web Socket

   - Styling : Storybook, Styled-Components

#### DB 테이블 및 스키마 (세부사항)

- Users (Auth Server 측) : 유저의 회원 가입 정보 및 프로필 정보를 가진다.

![전-PMP-계획서-image-4](images/전-PMP-계획서-image-4.png)

- Topics (해시태그) (API Server 측) : 관심 주제 목록 테이블 (N:N)

   - __id__ int AI PK

   - __topic__ varchar

- Feeds

   - __topic_id__ int FK

   - __tweet_id__ int FK

- Tweets (데이터 처리 측) : 하나의 트윗

   - __id__ int AI PK

   - __user_id__ int FK

   - __message__ varchar

   - __created_at__ datetime

   - __location_id__ int FK

   - __retweet__ int

   - __likes__ int

   - __quoted_counts__ int

- Keywords (데이터 처리 측): 처리한 데이터 목록 (N:N)

   - id int AI PK

   - topic_id int FK

   - keyword varchar

   - sentiment int

- Locations

   - __id__ int AI PK

   - __location__ varchar

![전-PMP-계획서-image-5](images/전-PMP-계획서-image-5.png)

#### API 명세서 (세부사항)

#### UI/UX 설계 (세부사항)

컨텐츠 분석, 키워드 분석, 연관어 비교

![전-PMP-계획서-image-6](images/전-PMP-계획서-image-6.png)

### 마일스톤 (일정)

#### M1 - 12/29 (화)

- PMP

- Adobe XD 또는 Figma를 활용하여 디자인 프로토타입 제작

- 실시간 Twitter API 응답 데이터 스키마 파악 (ex. #코로나)

- Twitter API 응답 데이터를 Kafka로 연동하기

- Spark 개발 환경 구축하기(설치&가상환경)

- Cassandra Data Modeling

- Cassandra DB를 Django와 연결하여 데이터 가져오는 API 서버 프로젝트 환경 구축하기

- 프론트 화면의 데이터 시각화 컴포넌트 구성

   - rechart, victory 등 차트 라이브러리 사용

- 프론트 화면의 UI 컴포넌트 구성

   - Ant Design, Material UI, React-Spectrum 등 UI 라이브러리 사용

#### M2 - 1/12 (화)

- 데이터 팀 공통 개발 환경 구축

   1. 데이터 통합 처리를 위한 AWS 서버 구축 및 환경 설정

   1. Cassandra DB, Spark, Kafka 개발 환경 구축

   1. twitter api에서 데이터 1개로 데이터 파이프라인 맞춰보기

   1. 실시간 피드 대시보드를 위한 키워드 '코로나'로 기능 구현하기

   1. 키워드 데이터 양(코로나+조사 포함) 늘려서 정상 작동 확인하기

   1. 가능하다면, 키워드 주제 한 가지 더 시도해보기

- 각자의 파이프라인 인터페이스 맞추기

- 실시간 피드를 제공하는 API 서버 구축하기

- 실시간 피드 저장하는 DB 스키마

#### M3 - 1/22(금)

- '코로나' 외 여러 주제로 확장하기 (5개 이상)

- 총 언급량, 개별 사용자 추이

#### M4 - 1/29 (금)

- 트랜드 분석

   1. 연관어 비교

   1. 키워드 분석(긍/부정)

#### M5- 2/5(금)

- 최종 발표 준비

- 오류수정

## 마일스톤 (PMP 제출)

### M1

> DevCamp 기간 내에 반드시 완료되어야 하는 목표

- 코로나 관련 키워드에 대한 트렌드 분석 제공

   - Keyword List

      - *코로나 12만 

      - *백신 38000 

      - *방역 36000

      - *확진자 46000

      - *여행 38000

- 특정 토픽에 대한 트윗을 실시간으로 제공하는 실시간 대시보드 웹 애플리케이션

   - 웹소켓을 사용한 실시간 피드 구현

- 기본 트렌드 분석 대시보드 구현

   ⇒ 총합, 평균 등 단순통계치 구현  ex) 총 언급량, 언급량 추이, 연관어 분석

- 데이터처리 Kafka-Spark-Cassandra 연결해서 데이터 통신 확인하기

- Spark-Streaming과 Spark Consumer, Spark Cassandra Connector 구현하기

- 키워드의 수에 따라 scale-out 가능한 구조를 설계하여 Kafka broker(topic 및 partition) 구현

- 유지보수가 원활하도록 분산 DB 구축 및 분석에 필요한 추가적인 데이터 모델링

- 트위터 소셜 로그인을 사용한 유저 인증

   - MSA로 분리되어 토큰 기반으로 인증하는 서버

- AWS 내에서 개발환경 구축 및 전체서비스 통합

- 기간별 데이터 제공

### M2

> DevCamp 기간 안에 어떻게든 최선을 다한다면 할 수 있을 것 같은 목표

- 코로나 주제 관련 키워드 확장하기

   - 재택 5000

   - 변이 2000

   - 사망 13000

   - 언택트 6000

   - 비대면 6000

   - 사회적거리두기 7000

- 추가적으로 분석 기법이 들어간 Trend 컴포넌트들을 완성(워드 클라우드, 버블 차트 등)

- 트위터와 상호작용할 수 있는 기능 구현 (좋아요, 리트윗, 댓글 등)

- 데이터 유실이 없도록(또는 속도와의 trade-off) Kafka 파라미터 튜닝 및 키워드 확장 적용

- DB 퍼포먼스 향상을 위한 튜닝

- 웹 서버와 웹 인터페이스 연결에 있어 API 게이트웨이를 통해 짜임새 있는 MSA 구조 구축 

- 트위터에서 제공하는 데이터 최대한 활용하여 통계 컴포넌트 늘리기 (사용자 위치, 작성 디바이스 등)

- 웹페이지 모바일 반응형 지원

- 랜딩 페이지 구축 (홈 화면, 서비스 소개)

### M3

> DevCamp 기간 내에는 불가능하지만 궁극적으로 만들고자 하는 목표

- 유저가 검색한 검색어 데이터 실시간 반영으로 확장하기 

   - 유저가 검색한 내용을 twitter API 의 파라미터로 입력해 실시간으로 데이터를 받아옴(유동적)

   - twitter API의 Sample Stream을 이용해 많은 양의 전체 tweets 의 수를 샘플링하여 감당할 수 있는 양의 데이터에서도 동향을 파악할 수 있도록 함

   - 해당 검색어와 코로나와의 상관성을 분석하여 인사이트 제공

- 분석 결과 개인 유저 별 저장

- 트위터 API 뿐만 아니라 다른 데이터 소스까지 확장(인스타그램 등)

- <details><summary>이전 마일스톤</summary>

   #### M1 - (마감일: 1/5)

   - Adobe XD 또는 Figma를 활용하여 디자인 프로토타입 제작

   - 실시간 Twitter API 응답 데이터 스키마 파악 (ex. #코로나)

   - Twitter API 응답 데이터를 Kafka로 연동하기

   - Kafka로 전달된 데이터를 Spark streaming으로 연동하기

   - Cassandra Data Modeling

   - Cassandra DB를 Django와 연결하여 데이터 가져오는 API 서버 프로젝트 환경 구축하기

   - 프론트 화면의 데이터 시각화 컴포넌트 구성

      - rechart, victory 등 차트 라이브러리 사용

   - 프론트 화면의 UI 컴포넌트 구성

      - Ant Design, Material UI, React-Spectrum 등 UI 라이브러리 사용

   #### M2 - (마감일: 1/12 - 중간 발표)

   - Django와 Spark를 연결하여 가공한 데이터 가져오는 API 서버 프로젝트 환경 구축하기

   - 프론트엔드 디자인시스템(컴포넌트 라이브러리) 개발 환경 구축

   - Twitter 실시간 stream API의 응답을 처리하여 연관어 추출하기

   - Twitter 실시간 stream API를 구동하여 DB에 데이터를 저장할 수 있는 환경 구축

      - 1개월 기간 DB저장

   - 분산형 DB에 접근하여 처리된 데이터를 가져오는 API 서버 구축

   - API 서버로부터 처리된 데이터를 가져와 프론트에서 데이터 시각화 컴포넌트로 보여주기

   #### M3 - (마감일: 1/29)

   - JWT를 활용한 토큰 기반 인증 서버 개발

   - 회원가입, 로그인 폼 페이지 제작

   - 유저 관심 키워드 입력 폼 제작

   - Micro Service Architecture로 인증 API 서버, 실시간 피드 API 서버, 키워드 API 서버 분리하기

   - Nginx를 활용하여 API Gateway 구성하고 API 서버 연결하기

   - 3개월 기간 DB 저장

   - 데이터 처리 확장 (키워드 개수 확대)

   - 데이터 분석을 위한 데이터 처리 시스템 구축

   - 프론트 페이지 레이아웃 및 디자인 수정

   - 발표 PPT 자료 준비

   #### M4 - (마감일: 2/5 - 최종 발표)

   - 특정 키워드가 아닌 유저의 검색에 의한 실시간 서비스로 확장(실시간 End-to-End 데이터 처리) 

   - 확장된 키워드 및 분석을 위한 데이터 시각화

   - 최종 기능 테스트

  </details>



[여승환 이사님 PMP 리뷰](여승환-이사님-PMP-리뷰/여승환-이사님-PMP-리뷰.md)

[여승환 이사님 공통 피드백 요약](여승환-이사님-공통-피드백-요약/여승환-이사님-공통-피드백-요약.md)

- 대시보드 형태 디자인

- 웹소켓 다뤄보기

## 개인 목표

- 솔직하고 구체적으로

- 정량적, 가시적

- PMP를 보고 자신을 돌아봤을 때 평가할 수 있도록

- PMP를 보고 다른 사람이 결과물을 봤을 때 평가할 수 있도록

### 이전 __팀 목표__

- 개발 방법

   - 짧은 주기로 기능 단위로 만들어서, 함께 통합해보는 과정 자주 반복하기

   - 점진적으로 개발하여 부족한 부분은 개선하고 필요한 부분은 추가하기

   - 애자일 방식으로 한 cycle 돌면서 반복적으로 피드백하고 수정해 나가기

- 서비스

   - 국내 서비스부터 시작해서 글로벌 서비스로 확장할 수 있는 확장성 제공하기

   - 안정적으로 운영되는 서버를 만들기

   - 대용량 DB 안정적으로 운영하기

- 팀워크

   - 개인 마일스톤이랑 목표를 달성함으로써 팀 목표를 달성하기

   - 기능 구현을 위해 새롭게 배운 내용이나 어려웠던 이슈 해결을 문서화하고 서로 공유하며 함께 성장하기

- 추가적 목표

   - 이후 4개월 기간 동안 배포 + 트래픽 늘리기에 도전해보기

