# 2021-01-06 멘토링

### Backend

- 실시간 API server 개발 중(Django, channels 이용한 Web socket)

- 실시간으로 업데이트되는 것을 확인하는 정도로 간단히 구현

- cassandra-B.E, B.E-F.E 사이의 연동은 아직

→ 실시간 기능을 위해선 cassandra를 계속 읽어야 함

→ 장고와 3rd party engine을 이용해서 연동 생각 중이지만 아직(RDB에서의 trigger 개념 적용 고려)

→ DB가 저장 외에 다른 기능(trigger)을 가지는 것은 호환성(바뀌는 경우)에 문제가 생길 수 있음..

    종속성을 제거하는 것이 좋음

→ scheduler(ex. 자바) 이용하여 서버에서 일정 주기마다 DB 에서 select 하는 방법 : 멘토님 의견

→ 실시간의 개념? 시간의 개념으로 기준을 정해야 함(0.1초든, 3초든)

### Frontend

- 글로벌 테마 정하고 차트 등의 컴포넌트를 하나씩 구현 중

- 백엔드-프론트 연동을 위한 tweet 컨텐츠 컴포넌트 개발 → 이번 주 내로 실시간 피드 완성 목표

- tweet 의 액션(좋아요, retweet 등)들의 적용(구현)을 고려 중

### Data Processing

- twitter API → kafka → spark streaming 의 연동은 됐지만 데이터 포멧의 처리 필요

- spark streaming → cassandra 연동은 아직

- spark streaming의 의미? :  중간에서 스트리밍에 필요한 작업(처리)을 함

→ kafka 에서 바로 저장하는 것도 가능(소규모 작업이라면) 하지만 raw 데이터와 성능 문제를 고려

ex) 5분마다 실시간 정보를 RDB 데이터를 select해서 1차 가공 후 HDFS 에 저장

- cassandra 파티션을 너무 많이 나누면 유실률이 문제 될 수 있지만 나누지 않는 것은 또 아님

→ 파티션, 토픽, 날짜(시간) 등 을 기준으로 나눌 수 있음

ex) HDFS 파티션: 특정 시점의 데이터 하나가 잘못(누락 등) 되었을 땐, 해당 파티션을 모두 다시 받아야 함. 초기 설계를 신중해야 이런 문제 방지할 수 있음

### 새로운 고려사항

1. 사용자나 관리자가 키워드를 추가할 수 있는 기능

→ 추가적인 API를 통해 DB에서 키워드를 관리해 twitter API에서 요청하는 데이터를 추가하도록..

→ 현재 유동적이지 못한 키워드 종류(하드코딩)를 유동적으로 할 수 있도록 계획해보기

